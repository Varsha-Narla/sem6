{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b732b21-374c-45e2-8742-ffdcc47a7e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\ewastesem6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\akshat103\\e-waste-image-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"akshat103/e-waste-image-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea803495-316b-42b0-8824-e2c3735d2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torchvision import datasets, transforms \n",
    "from torch.utils.data import DataLoader \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411c2784-a38f-4fcd-b4ef-6fd89b9deb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=r\"C:\\Users\\DELL\\OneDrive\\Desktop\\modified-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "234ba7db-b4b8-41fa-8f99-6ec636a64c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Directory: C:\\Users\\DELL\\OneDrive\\Desktop\\modified-dataset\n",
      "Subdirectories: ['test', 'train', 'val']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Directory:\", dataset_dir)\n",
    "print(\"Subdirectories:\", os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43a1ae7-b463-40f9-8c43-cffc244b44e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (dropout3): Dropout(p=0.3, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=50176, out_features=128, bias=True)\n",
      "  (dropout4): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.conv1=nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1=nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout2=nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout3=nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.flatten=nn.Flatten()\n",
    "        self.fc1=nn.Linear(64*28*28, 128)\n",
    "        self.dropout4=nn.Dropout(p=0.4)\n",
    "        self.fc2=nn.Linear(128, num_classes) \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(torch.relu(self.conv1(x)))\n",
    "        x=self.dropout1(x)\n",
    "        x=self.pool(torch.relu(self.conv2(x)))\n",
    "        x=self.dropout2(x)\n",
    "        x=self.pool(torch.relu(self.conv3(x)))\n",
    "        x=self.dropout3(x)\n",
    "        x=self.flatten(x)\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=self.dropout4(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device=\"cpu\"\n",
    "model=CNNModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a8b9cc-84a9-4c0c-9b88-11a9d259c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  ['Battery', 'Keyboard', 'Microwave', 'Mobile', 'Mouse', 'PCB', 'Player', 'Printer', 'Television', 'Washing Machine']\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "dataset_path=r\"C:\\Users\\DELL\\OneDrive\\Desktop\\modified-dataset\"\n",
    "train_dataset=datasets.ImageFolder(root=dataset_path+'/train', transform=transform)\n",
    "val_dataset=datasets.ImageFolder(root=dataset_path+'/val', transform=transform)\n",
    "test_dataset=datasets.ImageFolder(root=dataset_path+'/test', transform=transform)\n",
    "\n",
    "batch_size=32 \n",
    "train_loader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader=DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Classes: \", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0afb668a-3bbe-42bb-a882-db9eddf8a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(), lr=0.001, )\n",
    "\n",
    "num_epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e577f2-f41e-4ebf-8af4-992fde663cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - Train Loss: 1.8272, Train Acc: 36.67% - Val Loss: 1.7212, Val Acc: 44.33%\n",
      "Epoch [2/50] - Train Loss: 1.5699, Train Acc: 46.42% - Val Loss: 1.4085, Val Acc: 53.33%\n",
      "Epoch [3/50] - Train Loss: 1.3464, Train Acc: 53.25% - Val Loss: 1.3944, Val Acc: 62.00%\n",
      "Epoch [4/50] - Train Loss: 1.1705, Train Acc: 60.21% - Val Loss: 1.2894, Val Acc: 60.33%\n",
      "Epoch [5/50] - Train Loss: 0.9653, Train Acc: 66.83% - Val Loss: 1.2994, Val Acc: 59.33%\n",
      "Epoch [6/50] - Train Loss: 0.8111, Train Acc: 71.75% - Val Loss: 1.1984, Val Acc: 63.67%\n",
      "Epoch [7/50] - Train Loss: 0.6490, Train Acc: 77.71% - Val Loss: 1.2155, Val Acc: 62.67%\n",
      "Epoch [8/50] - Train Loss: 0.5293, Train Acc: 82.92% - Val Loss: 1.3031, Val Acc: 60.67%\n",
      "Epoch [9/50] - Train Loss: 0.4483, Train Acc: 85.00% - Val Loss: 1.2471, Val Acc: 63.33%\n",
      "Epoch [10/50] - Train Loss: 0.3526, Train Acc: 87.75% - Val Loss: 1.3060, Val Acc: 63.33%\n",
      "Epoch [11/50] - Train Loss: 0.3437, Train Acc: 87.92% - Val Loss: 1.3060, Val Acc: 63.67%\n",
      "Epoch [12/50] - Train Loss: 0.2859, Train Acc: 90.33% - Val Loss: 1.4596, Val Acc: 63.00%\n",
      "Epoch [13/50] - Train Loss: 0.2441, Train Acc: 91.29% - Val Loss: 1.5169, Val Acc: 63.33%\n",
      "Epoch [14/50] - Train Loss: 0.2216, Train Acc: 92.08% - Val Loss: 1.3575, Val Acc: 64.00%\n",
      "Epoch [15/50] - Train Loss: 0.1750, Train Acc: 94.25% - Val Loss: 1.5890, Val Acc: 65.00%\n",
      "Epoch [16/50] - Train Loss: 0.1655, Train Acc: 94.58% - Val Loss: 1.5018, Val Acc: 61.67%\n",
      "Epoch [17/50] - Train Loss: 0.1607, Train Acc: 94.75% - Val Loss: 1.6972, Val Acc: 61.00%\n",
      "Epoch [18/50] - Train Loss: 0.1546, Train Acc: 94.79% - Val Loss: 1.5167, Val Acc: 66.33%\n",
      "Epoch [19/50] - Train Loss: 0.1287, Train Acc: 95.50% - Val Loss: 1.6836, Val Acc: 64.00%\n",
      "Epoch [20/50] - Train Loss: 0.1405, Train Acc: 95.00% - Val Loss: 1.7537, Val Acc: 63.00%\n",
      "Epoch [21/50] - Train Loss: 0.1260, Train Acc: 95.21% - Val Loss: 1.6867, Val Acc: 66.67%\n",
      "Epoch [22/50] - Train Loss: 0.1673, Train Acc: 94.88% - Val Loss: 1.8289, Val Acc: 63.67%\n",
      "Epoch [23/50] - Train Loss: 0.1439, Train Acc: 95.04% - Val Loss: 1.7486, Val Acc: 62.00%\n",
      "Epoch [24/50] - Train Loss: 0.1323, Train Acc: 95.83% - Val Loss: 1.7819, Val Acc: 65.33%\n",
      "Epoch [25/50] - Train Loss: 0.1523, Train Acc: 95.08% - Val Loss: 1.7227, Val Acc: 66.00%\n",
      "Epoch [26/50] - Train Loss: 0.1087, Train Acc: 95.88% - Val Loss: 1.7015, Val Acc: 65.33%\n",
      "Epoch [27/50] - Train Loss: 0.0917, Train Acc: 96.75% - Val Loss: 1.6736, Val Acc: 67.00%\n",
      "Epoch [28/50] - Train Loss: 0.1117, Train Acc: 96.42% - Val Loss: 1.6545, Val Acc: 67.00%\n",
      "Epoch [29/50] - Train Loss: 0.0886, Train Acc: 96.58% - Val Loss: 1.8302, Val Acc: 65.00%\n",
      "Epoch [30/50] - Train Loss: 0.0961, Train Acc: 96.71% - Val Loss: 1.5321, Val Acc: 65.00%\n",
      "Epoch [31/50] - Train Loss: 0.0834, Train Acc: 97.04% - Val Loss: 1.5495, Val Acc: 65.67%\n",
      "Epoch [32/50] - Train Loss: 0.0951, Train Acc: 97.04% - Val Loss: 1.7192, Val Acc: 65.00%\n",
      "Epoch [33/50] - Train Loss: 0.1064, Train Acc: 96.54% - Val Loss: 1.6962, Val Acc: 64.67%\n",
      "Epoch [34/50] - Train Loss: 0.1299, Train Acc: 95.71% - Val Loss: 1.6308, Val Acc: 67.00%\n",
      "Epoch [35/50] - Train Loss: 0.0851, Train Acc: 96.96% - Val Loss: 1.8426, Val Acc: 65.33%\n",
      "Epoch [36/50] - Train Loss: 0.1020, Train Acc: 96.75% - Val Loss: 1.5863, Val Acc: 65.67%\n",
      "Epoch [37/50] - Train Loss: 0.0643, Train Acc: 97.92% - Val Loss: 1.8050, Val Acc: 65.67%\n",
      "Epoch [38/50] - Train Loss: 0.0713, Train Acc: 97.71% - Val Loss: 1.7928, Val Acc: 66.00%\n",
      "Epoch [39/50] - Train Loss: 0.0817, Train Acc: 97.46% - Val Loss: 1.9877, Val Acc: 63.33%\n",
      "Epoch [40/50] - Train Loss: 0.0827, Train Acc: 97.46% - Val Loss: 1.8962, Val Acc: 67.67%\n",
      "Epoch [41/50] - Train Loss: 0.0896, Train Acc: 97.00% - Val Loss: 1.8339, Val Acc: 67.00%\n",
      "Epoch [42/50] - Train Loss: 0.0830, Train Acc: 97.04% - Val Loss: 2.1777, Val Acc: 64.00%\n",
      "Epoch [43/50] - Train Loss: 0.0815, Train Acc: 97.46% - Val Loss: 1.7976, Val Acc: 66.67%\n",
      "Epoch [44/50] - Train Loss: 0.0801, Train Acc: 97.17% - Val Loss: 1.9186, Val Acc: 64.33%\n",
      "Epoch [45/50] - Train Loss: 0.0581, Train Acc: 98.12% - Val Loss: 1.9344, Val Acc: 65.00%\n",
      "Epoch [46/50] - Train Loss: 0.0753, Train Acc: 97.33% - Val Loss: 1.8529, Val Acc: 65.67%\n",
      "Epoch [47/50] - Train Loss: 0.0602, Train Acc: 97.79% - Val Loss: 1.8881, Val Acc: 64.00%\n",
      "Epoch [48/50] - Train Loss: 0.0680, Train Acc: 97.67% - Val Loss: 1.9114, Val Acc: 67.00%\n",
      "Epoch [49/50] - Train Loss: 0.0733, Train Acc: 97.62% - Val Loss: 1.8409, Val Acc: 65.00%\n",
      "Epoch [50/50] - Train Loss: 0.0717, Train Acc: 97.50% - Val Loss: 1.9901, Val Acc: 64.67%\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (num_epochs):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    correct_train=0\n",
    "    total_train=0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels=images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        _,predicted=torch.max(outputs, 1)\n",
    "        correct_train+=(predicted==labels).sum().item()\n",
    "        total_train+=labels.size(0)\n",
    "    train_loss=running_loss/len(train_loader)\n",
    "    train_accuracy=100*correct_train/total_train\n",
    "\n",
    "    model.eval()\n",
    "    val_loss=0.0\n",
    "    correct_val=0\n",
    "    total_val=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels=images.to(device), labels.to(device)\n",
    "            outputs=model(images)\n",
    "            loss=criterion(outputs, labels)\n",
    "            val_loss+=loss.item()\n",
    "\n",
    "            _, predicted=torch.max(outputs, 1)\n",
    "            correct_val+=(predicted==labels).sum().item()\n",
    "            total_val+=labels.size(0)\n",
    "\n",
    "    val_loss/=len(val_loader)\n",
    "    val_accuracy=100*correct_val/total_val\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% - \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5175e-edaa-4977-b2fc-193f3c57d863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
